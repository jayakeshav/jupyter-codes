{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "753f26d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "651c2bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "idle_directory = \"../data/combined data files/idle/\"\n",
    "attack_directory = \"../data/combined data files/spectre/\"\n",
    "\n",
    "idle_files = [file for file in os.listdir(idle_directory)]\n",
    "attack_files = [file for file in os.listdir(attack_directory)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36d0a0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to combine and save rows in batches of specified size\n",
    "def combine_in_batches(files, isIdle, output_file, batch_size):\n",
    "    batch_data = []\n",
    "    for file in files:\n",
    "        if isIdle:\n",
    "            fileName = idle_directory + file\n",
    "        else:\n",
    "            fileName = attack_directory + file\n",
    "#         \\print(fileName)\n",
    "        df = pd.read_csv(fileName)  # Read the CSV file\n",
    "        for i in range(0, len(df), batch_size):\n",
    "            batch = df.iloc[i:i + batch_size]  # Get a batch of rows\n",
    "            if len(batch) == batch_size:  # Only include full batches\n",
    "                batch_data.append(batch)\n",
    "    \n",
    "    # Concatenate all full batches\n",
    "    combined_df = pd.concat(batch_data, ignore_index=True)\n",
    "    combined_df.to_csv(output_file, index=False)  # Save to master file\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b662bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idle files combined into '../data/combined data files/combined_idle_batches.csv'\n",
      "Attack files combined into '../data/combined data files/combined_attack_batches.csv'\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "\n",
    "# Combine idle files with a batch size of 5 and save\n",
    "idle_combined_df = combine_in_batches(idle_files, True, \"../data/combined data files/combined_idle_batches.csv\", batch_size)\n",
    "print(\"Idle files combined into '../data/combined data files/combined_idle_batches.csv'\")\n",
    "\n",
    "# Combine attack files with a batch size of 5 and save\n",
    "attack_combined_df = combine_in_batches(attack_files, False,\"../data/combined data files/combined_attack_batches.csv\", batch_size)\n",
    "print(\"Attack files combined into '../data/combined data files/combined_attack_batches.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c4ddadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of idle_combined_df: (242670, 21)\n",
      "Size of attack_combined_df: (260155, 21)\n"
     ]
    }
   ],
   "source": [
    "# Print the sizes of the DataFrames\n",
    "print(f\"Size of idle_combined_df: {idle_combined_df.shape}\")\n",
    "print(f\"Size of attack_combined_df: {attack_combined_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ee75b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating batches...\n",
      "[==================================================] 100.00%\n",
      "\n",
      "Shuffling batches...\n",
      "\n",
      "Writing batches to CSV...\n",
      "[==================================================] 100.00%\n",
      "Shuffled data successfully written to CSV.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "# Function to generate a progress bar\n",
    "def progress_bar(current, total, bar_length=50):\n",
    "    progress = current / total\n",
    "    bar = '=' * int(progress * bar_length) + '-' * (bar_length - int(progress * bar_length))\n",
    "    sys.stdout.write(f'\\r[{bar}] {progress * 100:.2f}%')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# Function to write shuffled batches directly to CSV\n",
    "def write_shuffled_batches_to_csv(idle_df, attack_df, batch_size, output_file):\n",
    "    # Calculate the maximum number of batches that can be drawn from each DataFrame\n",
    "    max_batches_idle = len(idle_df) // batch_size\n",
    "    max_batches_attack = len(attack_df) // batch_size\n",
    "    total_batches = min(max_batches_idle, max_batches_attack) * 2  # Equal distribution\n",
    "    \n",
    "    # Initialize batch counters\n",
    "    idle_start, attack_start = 0, 0\n",
    "    batches = []\n",
    "    \n",
    "    print(\"\\nCreating batches...\")\n",
    "    for i in range(total_batches // 2):\n",
    "        # Create one batch from idle data\n",
    "        idle_batch = idle_df.iloc[idle_start:idle_start + batch_size].copy()\n",
    "        idle_batch['Label'] = 0  # Label for idle\n",
    "        batches.append(idle_batch)\n",
    "        idle_start += batch_size\n",
    "        \n",
    "        # Create one batch from attack data\n",
    "        attack_batch = attack_df.iloc[attack_start:attack_start + batch_size].copy()\n",
    "        attack_batch['Label'] = 1  # Label for attack\n",
    "        batches.append(attack_batch)\n",
    "        attack_start += batch_size\n",
    "        \n",
    "        # Update progress bar for batch creation\n",
    "        progress_bar(i + 1, total_batches // 2)\n",
    "    \n",
    "    # Shuffle the batches\n",
    "    print(\"\\n\\nShuffling batches...\")\n",
    "    np.random.shuffle(batches)\n",
    "    \n",
    "    # Write the shuffled batches to CSV\n",
    "    print(\"\\nWriting batches to CSV...\")\n",
    "    with open(output_file, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Write the header row\n",
    "        writer.writerow(list(idle_df.columns) + ['Label'])\n",
    "        \n",
    "        for i, batch in enumerate(batches):\n",
    "            writer.writerows(batch.values)\n",
    "            \n",
    "            # Update progress bar for writing batches\n",
    "            progress_bar(i + 1, len(batches))\n",
    "    \n",
    "    print(\"\\nShuffled data successfully written to CSV.\")\n",
    "\n",
    "# Specify batch size and output file\n",
    "batch_size = 5\n",
    "output_file = \"../data/combined data files/shuffled_master_data.csv\"\n",
    "\n",
    "# Write shuffled batches directly to CSV\n",
    "write_shuffled_batches_to_csv(idle_combined_df, attack_combined_df, batch_size, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f36bb16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master DataFrame saved to '../data/combined data files/master_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the master DataFrame to a new CSV file\n",
    "master_df.to_csv(\"../data/combined data files/master_data.csv\", index=False)\n",
    "print(\"Master DataFrame saved to '../data/combined data files/master_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43423d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
